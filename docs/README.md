# Security Data Platform Architecture Decision Tool

Interactive decision tool for filtering 71 security data platforms to 3-5 personalized finalists based on your organizational constraints.

## ðŸŽ¯ Purpose

Transform the decision framework from "Modern Data Stack for Cybersecurity" book into an accessible web-based tool that filters real vendors based on team size, budget, infrastructure patterns, and technical preferences.

## ðŸš€ Live Tool

**GitHub Pages URL:** `https://flying-coyote.github.io/security-architect-mcp-server/`

**Local Testing:** `http://localhost:8080/index-v2.html`

## âœ¨ Features (V3 - Sizing-First + Multi-Select + Sliders)

- **Sizing Constraints First:** 5 sliders (data volume 1 GB-100 TB, growth 0-300%, sources 1-500, retention 1d-7yr, budget $50K-$50M)
- **Architecture-First Ordering:** Sizing â†’ Foundational Architecture â†’ Organizational Constraints â†’ Use Cases
- **Multi-Select Support:** Query engine (F4) and cloud environment (Q3) allow multiple selections (e.g., AWS + Azure + on-prem)
- **Enhanced UX:** Deselectable radio buttons (click to unselect), logarithmic sliders, real-time vendor filtering
- **14 Questions Total:** 5 sliders (S1-S4, Q2), 6 single-select (F0-F3, Q1, Q4), 3 multi-select (F4, Q3, Q5)
- **Actual Vendor Filtering:** 71 vendors filtered to 3-5 finalists based on your answers
- **Top 5 Vendor Display:** See vendor names, descriptions, costs, and capabilities
- **Performance Impact Analysis:** 0% vs 15-50% RLS overhead implications
- **TCO Guidance:** OSS catalogs ($0) vs Unity Catalog ($10K-50K/year)
- **Production Validation:** Examples from Netflix, Huntress, Okta, Arctic Wolf
- **Enhanced Downloadable Report:** Full vendor recommendations with capabilities, costs, and next steps

## ðŸ“Š Decision Flow (V3 - Sizing-First Architecture)

```
PHASE 0: SIZING CONSTRAINTS (eliminate by scale)
S1: Data Volume (1 GB - 100 TB/day)
â”œâ”€ <10 GB/day â†’ DuckDB viable, Splunk overkill
â”œâ”€ 10-100 GB/day â†’ Most distributed engines viable
â”œâ”€ 100 GB-1 TB/day â†’ Eliminate single-process engines (DuckDB)
â””â”€ 1+ TB/day â†’ Require distributed query engines (Trino, Spark, ClickHouse)

S2: Annual Growth Rate (0-300%)
â”œâ”€ <50% â†’ Stable capacity planning
â”œâ”€ 50-150% â†’ Plan for 2-3Ã— growth
â””â”€ 150%+ â†’ Elastic/serverless strongly preferred

S3: Data Source Count (1-500 sources)
â”œâ”€ <10 sources â†’ Manual ingestion viable
â”œâ”€ 10-50 sources â†’ ETL orchestration (Airflow, dbt)
â””â”€ 50+ sources â†’ Enterprise ETL required (Fivetran, Airbyte)

S4: Retention Requirement (1 day - 7 years)
â”œâ”€ 1-7 days â†’ Real-time detection, hot storage only
â”œâ”€ 30-90 days â†’ Compliance minimum (GDPR)
â”œâ”€ 1-2 years â†’ Fraud/forensics investigations
â””â”€ 3-7 years â†’ SOX, HIPAA, financial regulations

PHASE 1: FOUNDATIONAL ARCHITECTURE (establishes commitments)
F0: Isolation Pattern (KEY DECISION)
â”œâ”€ Isolated (security VPC) â†’ Polaris/Nessie ($0), 0% RLS overhead, Iceberg
â”œâ”€ Shared (PII+security) â†’ Unity Catalog (REQUIRED), 15-50% overhead, Delta/Iceberg
â””â”€ Multi-tenant MSSP â†’ Unity Catalog (REQUIRED), 5-30% overhead

F1: Table Format Preference
â”œâ”€ Iceberg â†’ 28 vendors (vendor-neutral, broad support)
â”œâ”€ Delta Lake â†’ 15 vendors (Databricks ecosystem)
â””â”€ No preference â†’ Derived from F0 isolation pattern

F2: Catalog Strategy
â”œâ”€ Polaris/Nessie â†’ OSS, $0 cost, isolation-first pattern
â”œâ”€ Unity Catalog â†’ $10K-50K/year, shared platforms, RLS overhead
â””â”€ AWS Glue/Azure Purview â†’ Cloud-native, managed service

F3: Transformation Approach
â”œâ”€ dbt Core â†’ SQL-based, OSS, Git workflows
â”œâ”€ Spark/Flink â†’ Complex transformations, streaming
â””â”€ Cloud ETL â†’ Managed services (Glue, Data Factory)

F4: Query Engine Characteristics (MULTI-SELECT)
â–¡ Low-latency (<3s) â†’ ClickHouse, Pinot
â–¡ High-concurrency (100+ users) â†’ Trino, Presto
â–¡ Serverless (auto-scaling) â†’ Athena, Snowflake
â–¡ Cost-optimized â†’ DuckDB, Parquet + S3

PHASE 2: ORGANIZATIONAL CONSTRAINTS (filter within architecture)
Q1: Team Capacity
â”œâ”€ Lean (1-2 engineers) â†’ Managed services required
â”œâ”€ Standard (3-5 engineers) â†’ Hybrid viable
â””â”€ Large (6+ engineers) â†’ Full composable stack manageable

Q2: Annual Budget Slider ($50K - $50M/year)
â”œâ”€ <$500K â†’ Eliminate Unity Catalog, Databricks, Snowflake, Splunk
â”œâ”€ $500K-$2M â†’ Balanced OSS + managed services
â”œâ”€ $2M-$10M â†’ Full vendor landscape available
â””â”€ $10M+ â†’ Cost less constrained

Q3: Cloud Environment (MULTI-SELECT)
â–¡ AWS â†’ AWS-native bonus (Athena, Glue)
â–¡ Azure â†’ Azure-native bonus (Synapse)
â–¡ GCP â†’ GCP-native bonus (BigQuery)
â–¡ Multi-cloud â†’ Cloud-agnostic required (Trino, Iceberg)
â–¡ On-premises â†’ Hybrid support required

Q4: Vendor Relationship Tolerance
â”œâ”€ OSS-first â†’ Community support, maximum flexibility
â”œâ”€ OSS with commercial support â†’ Vendor SLAs for OSS products
â””â”€ Commercial only â†’ 24/7 support, legal accountability

PHASE 3: USE CASES (score on fit)
Q5: Primary Use Cases (MULTI-SELECT)
â–¡ Real-time dashboards â†’ ClickHouse (1-3s P95)
â–¡ Ad-hoc hunting â†’ DuckDB (laptop), Trino (team-wide)
â–¡ Compliance reporting â†’ Athena (serverless), Trino (scheduled)
â–¡ Detection rules â†’ Kafka + Flink (streaming)
```

## ðŸŽ¨ Key Design Decisions (V3)

### Why Sizing-First Ordering?

**Problem with Constraint-First (V2):** Asking team size and budget before sizing wastes time on vendors that can't handle your data volume (e.g., DuckDB for 10 TB/day) or are overkill for small datasets (e.g., Splunk for 1 GB/day).

**Solution (V3):** Size-based elimination FIRST (data volume, growth, sources, retention) â†’ THEN establish foundational architecture â†’ THEN filter on organizational constraints (team, budget, cloud).

**Impact:** Vendors eliminated by scale before asking about preferred table format or budget. Aligns with proven MCP server architecture-first approach.

### Why Multi-Select for Query Engine and Cloud?

**Problem with Single-Select:** Most architectures need MULTIPLE capabilities:
- Query engine: Low-latency dashboards + high-concurrency analysts + serverless reports
- Cloud: AWS production + Azure DR, or AWS + on-prem hybrid

**Solution:** F4 (query engine) and Q3 (cloud environment) use checkboxes (multi-select), vendors SCORED on how many requirements they meet instead of hard filtering.

**Impact:** Better UX - express complex needs (need BOTH low-latency AND high-concurrency), vendors ranked by fit instead of eliminated.

### Why Logarithmic Sliders for Sizing?

**Problem with Fixed Options:** Data volume (0.1 GB - 100 TB) and budget ($50K - $50M) span 6 orders of magnitude. Fixed options (Small/Medium/Large) lack precision.

**Solution:** Logarithmic sliders with labeled markers (1 GB, 10 GB, 100 GB, 1 TB, 10 TB, 100 TB) provide intuitive UX for exponential ranges.

**Impact:** More granular specification, better vendor matching on actual data scale.

### Why Deselectable Radio Buttons?

**Problem with Standard Radios:** Users can't unselect an option once clicked, forcing restart to change answer.

**Solution:** Click-to-deselect pattern using CSS class tracking. Click selected radio â†’ deselects it â†’ returns to unanswered state.

**Impact:** Better UX for exploration and decision refinement.

## ðŸ› ï¸ Technical Stack

- **Pure Client-Side:** HTML, CSS, JavaScript (no server needed)
- **Vendor Database:** `vendor_database.json` (71 vendors with capabilities matrix)
- **Decision Data:** `decision-data-v3.json` (14 questions: 5 sliders, 6 single-select, 3 multi-select)
- **Hosting:** GitHub Pages (free, fast CDN)
- **Mobile-Responsive:** Works on desktop, tablet, mobile
- **No Dependencies:** Vanilla JS, no frameworks required

## ðŸ“ File Structure

```
docs/
â”œâ”€â”€ index.html                 # V3 default landing page (GitHub Pages entry)
â”œâ”€â”€ index-v2.html              # V3 interactive form (same as index.html)
â”œâ”€â”€ styles-v2.css              # V3 styling: two-column layout, sliders, multi-select
â”œâ”€â”€ decision-tree-v2.js        # V3 filtering logic: 4-phase filtering, multi-select scoring
â”œâ”€â”€ decision-data-v3.json      # V3 sizing-first question ordering (S1-S4, F0-F4, Q1-Q5)
â”œâ”€â”€ vendor_database.json       # 71 vendors with capability matrix
â”œâ”€â”€ README.md                  # This file
â””â”€â”€ SUBSTACK-INTEGRATION.md    # Blog integration guide
```

## ðŸš¢ Deployment to GitHub Pages

### Option 1: Automatic (GitHub Settings)

1. **Push to GitHub:**
   ```bash
   git add docs/
   git commit -m "ðŸŽ¯ Decision Tree V3 - Sizing-first + multi-select + sliders"
   git push origin main
   ```

2. **Enable GitHub Pages:**
   - Go to repository Settings â†’ Pages
   - Source: Deploy from a branch
   - Branch: `main`
   - Folder: `/docs`
   - Save

3. **Access:**
   - Wait 1-2 minutes for deployment
   - Visit: `https://flying-coyote.github.io/security-architect-mcp-server/`

### Option 2: Test Locally First

```bash
# Navigate to project root
cd /home/jerem/security-architect-mcp-server

# Start simple HTTP server (Python 3) serving docs/
python3 -m http.server 8080 --directory docs

# Open in browser
# http://localhost:8080/index.html (or index-v2.html)
```

Test all questions (sliders, single-select, multi-select), validate vendor filtering, then deploy to GitHub Pages.

## ðŸ”— Integration with Substack Blog

See `SUBSTACK-INTEGRATION.md` for complete blog integration guide.

### Quick Integration

**Post #11: "How to Filter 71 Security Data Platforms to 3 Finalists in 5 Minutes"**
```markdown
# How to Filter 71 Security Data Platforms to 3 Finalists in 5 Minutes

Before this tool, filtering the security data platform landscape took 2-4 weeks
of vendor research, architecture analysis, and cost modeling.

Now: 14 questions (5 sliders + 9 choices), 5 minutes, 3-5 personalized finalists.

**Try the interactive decision tool â†’**
https://flying-coyote.github.io/security-architect-mcp-server/

[Screenshot of vendor filtering in action with sliders and multi-select]
```

## ðŸ“ˆ Vendor Filtering Examples

### Example 1: Cost-Conscious Startup
**Sizing:**
- **S1:** 50 GB/day data volume
- **S2:** 100% annual growth
- **S3:** 15 data sources
- **S4:** 90 days retention

**Foundational Architecture:**
- **F0:** Isolated (security VPC)
- **F1:** Iceberg (vendor-neutral)
- **F2:** Polaris (OSS catalog)
- **F3:** dbt Core
- **F4:** High-concurrency + Cost-optimized (multi-select)

**Organizational Constraints:**
- **Q1:** Lean (1-2 engineers)
- **Q2:** $200K budget
- **Q3:** AWS (single cloud)
- **Q4:** OSS-first

**Use Cases:**
- **Q5:** Ad-hoc hunting + Compliance reporting (multi-select)

**Result:** 71 â†’ 8 vendors (DuckDB, Athena, Trino, MinIO, Polaris, Nessie, Iceberg, Parquet)
**Top 3:** DuckDB + Athena + Polaris (total TCO: <$50K/year)

### Example 2: Enterprise MSSP
**Sizing:**
- **S1:** 5 TB/day data volume
- **S2:** 150% annual growth
- **S3:** 200 data sources
- **S4:** 2 years retention

**Foundational Architecture:**
- **F0:** Multi-tenant MSSP
- **F1:** Delta Lake
- **F2:** Unity Catalog (required for RLS)
- **F3:** Spark
- **F4:** Low-latency + High-concurrency + Serverless (multi-select)

**Organizational Constraints:**
- **Q1:** Large (6+ engineers)
- **Q2:** $5M budget
- **Q3:** AWS + Azure (multi-cloud, multi-select)
- **Q4:** Commercial only

**Use Cases:**
- **Q5:** All use cases (dashboards + hunting + compliance + detection, multi-select)

**Result:** 71 â†’ 5 vendors (Databricks, Unity Catalog, Delta Lake, ClickHouse, Kafka)
**Top 3:** Databricks + Unity Catalog + ClickHouse (total TCO: $1.5M-3M/year)

## ðŸŽ¨ Customization

### Update Vendor Database

Edit `vendor_database.json`:
```json
{
  "vendors": [
    {
      "id": "new-vendor",
      "name": "New Vendor",
      "category": "Query Engine",
      "description": "...",
      "capabilities": {
        "iceberg_support": true,
        "operational_complexity": "low",
        "managed_service_available": true
      },
      "typical_annual_cost_range": "$50K-200K annually"
    }
  ]
}
```

### Add New Questions

Edit `decision-data-v3.json`:
```json
{
  "questions": [
    {
      "id": "q6_new_question",
      "order": 15,
      "section": "Additional Constraints",
      "title": "New Question",
      "type": "single_choice",
      "required": true,
      "options": [...]
    }
  ]
}
```

For sliders, use:
```json
{
  "id": "s5_new_sizing",
  "order": 5,
  "section": "Sizing Constraints",
  "title": "New Slider",
  "type": "slider",
  "min": 1,
  "max": 1000,
  "default": 100,
  "scale": "logarithmic",
  "unit": "TB/day",
  "markers": [1, 10, 100, 1000]
}
```

### Styling

Edit `styles-v2.css`:
```css
:root {
    --primary-color: #2563eb;  /* Change primary color */
    --secondary-color: #10b981;
}
```

## ðŸ¤ Contributing

This tool is part of the Security Data Commons project. Improvements welcome:

1. Fork repository
2. Create feature branch
3. Test changes locally (`python3 -m http.server 8080 --directory docs`)
4. Submit pull request

## ðŸ“„ License

- **Code:** Apache 2.0 (open source)
- **Content:** CC BY-SA 4.0 (attribution required)
- **Vendor Database:** Evidence-based from book research (no vendor sponsorships)

## ðŸ“š Related Resources

- **Blog:** https://securitydatacommons.substack.com
- **Book:** "Modern Data Stack for Cybersecurity" by Jeremy Wiley
- **GitHub:** https://github.com/flying-coyote/security-architect-mcp-server
- **MCP Server:** Conversational decision support (Claude Desktop integration)

## ðŸ› Issues & Feedback

Report issues: https://github.com/flying-coyote/security-architect-mcp-server/issues

---

**Generated with:** Claude Code via Happy
**Last Updated:** 2025-11-24 (V3 release: sizing-first + multi-select + sliders)
